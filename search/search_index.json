{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Learning Collection Site","text":"<p>Just my collection all I learned during the work time and other times.</p>"},{"location":"interviews/knowledge/","title":"Machine Learning interview Questions","text":""},{"location":"interviews/knowledge/#top-machine-learning-interview-questions","title":"Top Machine Learning Interview Questions","text":"<p>Material resources: link</p> <ol> <li>What Are the Different Types of Machine Learning?</li> </ol> <p>There are three types of machine learning: </p> <ul> <li> <p>Supervised Learning In supervised machine learning, a model makes predictions or decisions based on past or labeled data. Labeled data refers to sets of data that are given tags or labels, and thus made more meaningful.</p> </li> <li> <p>Unsupervised Learning In unsupervised learning, we don\u2019t have labeled data. A model can identify patterns, anomabiles, and relationships in the input data.</p> </li> <li> <p>Reinforcement Learning Using reinforcement learning, the model can learn based on the rewards it received for its previous action.Consider an environment where an agent is working. The agent is given a target to achieve. Every time the agent takes some action toward the target, it is given positive feedback. And, if the action taken is going away from the goal, the agent is given negative feedback. </p> </li> <li> <p>What is Overfitting, and How Can You Avoid It?</p> <p>The Overfitting is a situation that occurs when a model learns the training set too well, taking up random fluctuations in the training data as concepts. These impact the model\u2019s ability to generalize and don\u2019t apply to new data.  When a model is given the training data, it shows 100 percent accuracy-technically a slight loss. But, when we use the test data, there may be an error and low efficiency. This condition is known as overfitting.</p> <p>There are multiple ways of avoiding overfitting, such as: </p> <ul> <li>Regularization. It involves a cost term for the features involved with the objective function.</li> <li>Making a simple model. with lesser variables and parameters, the variance can be reduced. </li> <li>Cross-validation methods like k-folds can also be used. </li> <li>if some model parameters are likely to cause overfitting, techniques for regularization like LASSO can be used that penalize these parameters. </li> </ul> </li> <li> <p>What is \u2018training Set\u2019 and \u2018test Set\u2019 in a Machine Learning Model? How Much Data will You Allocate for Your Training, Validation, and Test Sets? </p> <p>There is a three-step process followed to create a model:  * Train the model * Test the model * Deploy the model </p> <p>Training Set</p> <ul> <li>The training set is examples given to the model to analyze and learn.</li> <li>70% of the total data is typically taken as the training dataset. </li> <li>This is labeled data used to train the model.</li> </ul> <p>Test Set</p> <ul> <li>The test set is used to test the arccuracy of the hypothesis generated by the model.</li> <li>Remaining 30% is taken as testing dataset.</li> <li>We test without labeled data and then verify results with labels.</li> </ul> </li> <li> <p>How Do You Handle Missing or Corrupted Data in a Dataset?</p> </li> </ul>"},{"location":"ml-ai/google-ml-crash-course/","title":"Google Machine Learning Crash Course","text":"<p>Course Link</p>"},{"location":"ml-ai/google-ml-crash-course/#framing-key-ml-terminology","title":"Framing: Key ML Terminology","text":"<ul> <li>ML systems learn how to combine input to produce useful predictions on never-before-seen data.</li> </ul>"},{"location":"ml-ai/google-ml-crash-course/#labels","title":"Labels","text":"<p>A label is the thing we\u2019re predicting\u2014the y variable in simple linear regression. The label could be the future price of wheat, the kind of animal shown in a picture, the meaning of an audio clip, or just about anything.</p>"},{"location":"ml-ai/google-ml-crash-course/#features","title":"Features","text":"<p>A feature is an input variable\u2014the x variable in simple linear regression. A simple machine learning project might use a single feature, while a more sophisticated machine learning project could use millions of features, </p> <ul> <li> <p>In the spam detector example, the features could include the following:</p> <ul> <li>words in the email text</li> <li>sender\u2019s address</li> <li>time of day the email was sent</li> <li>email contains the phrase \u201cone weird trick.\u201d</li> </ul> </li> </ul>"},{"location":"ml-ai/google-ml-crash-course/#examples","title":"Examples","text":"<p>An example is a particular instance of data, x. (We put x in boldface to indicate that it is a vector.) We break examples into two categories:</p>"},{"location":"ml-ai/google-ml-crash-course/#labeled-examples","title":"labeled examples","text":"<p>A labeled example includes both feature(s) and the label. That is:</p> <pre><code>labeled examples: {features, label}: (x, y)\n</code></pre> <p>Use labeled examples to train the model. In our spam detector example, the labeled examples would be individual emails that users have explicitly marked as \u201cspam\u201d or \u201cnot spam.\u201d</p>"},{"location":"ml-ai/google-ml-crash-course/#unlabeled-examples","title":"unlabeled examples","text":"<p>An unlabeled example contains features but not the label. That is:</p> <pre><code>unlabeled examples: {features, ?}: (x, ?)\n</code></pre>"},{"location":"ml-ai/google-ml-crash-course/#models","title":"Models","text":"<p>A model defines the relationship between features and label. For example, a spam detection model might associate certain features strongly with \u201cspam\u201d. Let\u2019s highlight two phases of a model\u2019s life:</p> <ul> <li> <p>Training means creating or learning the model. That is, you show the model labeled examples and enable the model to gradually learn the relationships between features and label.</p> </li> <li> <p>Inference means applying the trained model to unlabeled examples. That is, you use the trained model to make useful predictions (y\u2019). For example, during inference, you can predict medianHouseValue for new unlabeled examples.</p> </li> </ul>"},{"location":"ml-ai/google-ml-crash-course/#regression-vs-classification","title":"Regression vs Classification","text":"<ol> <li> <p>A regression model predicts continuous values. For example, regression models make predictions that answer questions like the following:</p> </li> <li> <p>What is the value of a house in California?</p> </li> <li> <p>What is the probability that a user will click on this ad?</p> </li> <li> <p>A classification model predicts discrete values. For example, classification models make predictions that answer questions like the following:</p> </li> <li> <p>Is a given email message spam or not spam?</p> </li> <li>Is this an image of a dog, a cat, or a hamster?</li> </ol>"},{"location":"ml-ai/google-ml-crash-course/#descending-into-ml","title":"Descending into ML","text":"<p>Training a model simply means learning (determining) good values for all the weights and the bias from labeled examples.</p> <p>Mean square error (MSE) is the average squared loss per example over the whole dataset. </p>"},{"location":"ml-ai/google-ml-crash-course/#reducing-lossgradient-descent","title":"Reducing Loss:Gradient Descent","text":"<p>Hyperparameters are the knobs that programmers tweak in machine learning algorithms.</p>"},{"location":"ml-ai/google-ml-crash-course/#introduction-to-tensorflow","title":"Introduction to TensorFlow","text":""},{"location":"ml-ai/google-ml-crash-course/#linear-regression-with-synthetic-data","title":"Linear Regression with Synthetic Data","text":"<p>Summary of hyperparameter tuning Most machine learning problems require a lot of hyperparameter tuning. Unfortunately, we can\u2019t provide concrete tuning rules for every model. Lowering the learning rate can help one model converge efficiently but make another model converge much too slowly. You must experiment to find the best set of hyperparameters for your dataset. That said, here are a few rules of thumb:</p> <ul> <li>Training loss should steadily decrease, steeply at first, and then more slowly until the slope of the curve reaches or approaches zero.</li> <li>If the training loss does not converge, train for more epochs.</li> <li>If the training loss decreases too slowly, increase the learning rate. Note that setting the learning rate too high may also prevent training loss from converging.</li> <li>If the training loss varies wildly (that is, the training loss jumps around), decrease the learning rate.</li> <li>Lowering the learning rate while increasing the number of epochs or the batch size is often a good combination.</li> <li>Setting the batch size to a very small batch number can also cause instability. First, try large batch size values. Then, decrease the batch size until you see degradation.</li> <li>For real-world datasets consisting of a very large number of examples, the entire dataset might not fit into memory. In such cases, you\u2019ll need to reduce the batch size to enable a batch to fit into memory.</li> </ul> <p>Remember: the ideal combination of hyperparameters is data dependent, so you must always experiment and verify.</p> <p>A correlation matrix indicates how each attribute\u2019s raw values relate to the other attributes\u2019 raw values. Correlation values have the following meanings:</p> <ul> <li>1.0: perfect positive correlation; that is, when one attribute rises, the other attribute rises.</li> <li>-1.0: perfect negative correlation; that is, when one attribute rises, the other attribute falls.</li> <li>0.0: no correlation; the two columns are not linearly related.</li> </ul> <p>In general, the higher the absolute value of a correlation value, the greater its predictive power. For example, a correlation value of -0.8 implies far more predictive power than a correlation of -0.2.</p>"},{"location":"ml-ai/ml/","title":"Core Concept of Machine Learning","text":""},{"location":"ml-ai/ml/#machine-learning-for-everyone-blog-link","title":"Machine Learning for Everyone Blog link","text":""},{"location":"ml-ai/ml/#three-components-of-machine-learning","title":"Three components of machine learning","text":"<ul> <li>Data </li> <li>Features</li> <li>Algorithms </li> </ul>"},{"location":"ml-ai/ml/#learning-vs-intelligence","title":"Learning vs Intelligence","text":"<ul> <li> <p>Aritificial intelligence is the name of a whole knowledge field, similar to biology or chemistry</p> </li> <li> <p>Machine Learning is a part of artificial intelligence. An important part, but not the only one. </p> </li> <li> <p>Neural Networks are one of machine learning types. A popular one, but there are other good guys in the class.</p> </li> <li> <p>Deep Learning is a modern method of building, training, and using neural networks. </p> </li> </ul> <p></p>"},{"location":"ml-ai/ml/#the-map-of-the-machine-learning-world","title":"The map of the machine learning world","text":"<ul> <li>Full view of machine learning</li> </ul> <ul> <li>Four main directions in machine learning</li> </ul>"},{"location":"ml-ai/ml/#part-1-classic-machine-learning","title":"Part 1. Classic Machine Learning","text":""},{"location":"ml-ai/ml/#11-supervised-learning","title":"1.1 Supervised Learning","text":"<p>the machine has a \u201csupervisor\u201d or a \u201cteacher\u201d who gives the machine all the answers, like whether it\u2019s a cat in the picture or a dog. The teacher has already divided (labeled) the data into cats and dogs, and the machine is using these examples to learn. One by one. Dog by cat.</p> <ul> <li>There are two types of such tasks: classification \u2013 an object\u2019s category prediction, and regression \u2013 prediction of a specific point on a numeric axis.</li> </ul>"},{"location":"ml-ai/ml/#classifications","title":"Classifications","text":"<ul> <li>\u201cSplits objects based at one of the attributes known beforehand. Separate socks by based on color, documents based on language, music by genre\u201d</li> </ul> <ul> <li> <p>Today used for:</p> <ul> <li>Spam filtering</li> <li>Language detection</li> <li>A search of similar documents</li> <li>Sentiment analysis</li> <li>Recognition of handwritten characters and numbers</li> <li>Fraud detection</li> </ul> </li> <li> <p>Popular algorithms:</p> <ul> <li>Naive Bayes</li> <li>Decision Tree</li> <li>Logistic Regression</li> <li>K-Nearest Neighbours</li> <li>Support Vector Machine</li> </ul> </li> <li> <p>Support Vector Machines (SVM) is rightfully the most popular method of classical classification. It was used to classify everything in existence: plants by appearance in photos, documents by categories, etc.</p> </li> </ul>"},{"location":"ml-ai/ml/#regression","title":"Regression","text":"<ul> <li>\u201cDraw a line through these dots. Yep, that\u2019s the machine learning\u201d</li> </ul> <ul> <li> <p>Today this is used for:</p> <ul> <li>Stock price forecasts</li> <li>Demand and sales volume analysis</li> <li>Medical diagnosis</li> <li>Any number-time correlations</li> <li>Popular algorithms are linear and Polynomial regressions.</li> </ul> </li> </ul>"},{"location":"ml-ai/ml/#12-unsupervised-learning","title":"1.2 Unsupervised Learning","text":""},{"location":"ml-ai/ml/#clustering","title":"Clustering","text":"<ul> <li>\u201cDivides objects based on unknown features. Machine chooses the best way\u201d</li> </ul> <ul> <li> <p>Nowadays used:</p> <ul> <li>For market segmentation (types of customers, loyalty)</li> <li>To merge close points on a map</li> <li>For image compression</li> <li>To analyze and label new data</li> <li>To detect abnormal behavior</li> </ul> </li> </ul> <p>popular algorithms: K-means_clustering, Mean-Shift, DBSCAN * The 5 Clustering Algorithms Data Scientists Need to Know</p>"},{"location":"ml-ai/ml/#dimensionality-reductiongeneralization","title":"Dimensionality-Reduction(Generalization)","text":"<ul> <li> <p>\u201cAssembles specific features into more high-level ones\u201d</p> </li> <li> <p>Nowadays is used for:</p> <ul> <li>Recommender systems (\u2605)</li> <li>Beautiful visualizations</li> <li>Topic modeling and similar document search</li> <li>Fake image analysis</li> <li>Risk management</li> </ul> </li> <li> <p>Popular algorithms: Principal Component Analysis (PCA), Singular Value Decomposition (SVD), Latent Dirichlet allocation (LDA), Latent Semantic Analysis (LSA, pLSA, GLSA), t-SNE (for visualization)</p> </li> </ul>"},{"location":"ml-ai/ml-az/data-processing/","title":"Part1 Data Pre-Processing","text":""},{"location":"ml-ai/ml-az/data-processing/#machine-learning-process","title":"Machine Learning process","text":""},{"location":"ml-ai/ml-az/data-processing/#data-pre-processing","title":"Data Pre-Processing","text":"<ul> <li>Import the data</li> <li>Clean the data</li> <li>Split into training &amp; test sets.</li> <li>Feature Scaling</li> </ul>"},{"location":"ml-ai/ml-az/data-processing/#modelling","title":"Modelling","text":"<ul> <li>Build the model </li> <li>Train the model</li> <li>Make predictions</li> </ul>"},{"location":"ml-ai/ml-az/data-processing/#evaluation","title":"Evaluation","text":"<ul> <li>Calculate perfomance metrics</li> <li>Make a verdict</li> </ul>"},{"location":"ml-ai/ml-az/data-processing/#feature-scalling-basic","title":"Feature Scalling Basic","text":""},{"location":"ml-ai/ml-az/data-processing/#data-pre-processing-template","title":"Data Pre-Processing Template","text":""},{"location":"ml-ai/ml-az/data-processing/#importing-the-libraries","title":"Importing the libraries","text":"<pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib as plt\n</code></pre>"},{"location":"ml-ai/ml-az/data-processing/#import-the-dataset","title":"Import the dataset","text":"<pre><code>dataset = pd.read_csv('data.csv')\n## Not include last column\nX = dataset.iloc[:, :-1]\n## only include last column\ny = dataset.iloc[:, -1]\n</code></pre>"},{"location":"ml-ai/ml-az/data-processing/#spliting-the-dataset-into-the-training-set-and-test-set","title":"Spliting the dataset into the Training set and Test set","text":"<pre><code>from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n</code></pre>"},{"location":"ml-ai/ml-az/data-processing/#featur-scaling","title":"Featur Scaling","text":"<pre><code>from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)\n</code></pre>"},{"location":"ml-ai/ml-az/regression/","title":"Regression","text":""},{"location":"ml-ai/ml-az/regression/#machine-learning-regression-models","title":"Machine Learning Regression models","text":"<ul> <li> <p>Simple Linear Regression</p> </li> <li> <p>Multiple Linear Regression</p> </li> <li> <p>Polynomial Regression</p> </li> <li> <p>Support Vector for Regression (SVR)</p> </li> <li> <p>Decision Tree Regression</p> </li> <li> <p>Random Forest Regression</p> </li> </ul> <p></p>"},{"location":"ml-ai/ml-az/regression/#regression-evaluation-metrics","title":"Regression evaluation metrics","text":"<p>Based on the differences between the predicted and actual values, you can calculate some common metrics that are used to evaluate a regression model.</p>"},{"location":"ml-ai/ml-az/regression/#mean-absolute-error-mae","title":"Mean Absolute Error (MAE)","text":"<p>The variance in this example indicates by how many ice creams each prediction was wrong. It doesn\u2019t matter if the prediction was over or under the actual value (so for example, -3 and +3 both indicate a variance of 3). This metric is known as the absolute error for each prediction, and can be summarized for the whole validation set as the mean absolute error (MAE).</p>"},{"location":"ml-ai/ml-az/regression/#mean-squared-error-mse","title":"Mean Squared Error (MSE)","text":"<p>The mean absolute error metric takes all discrepancies between predicted and actual labels into account equally. However, it may be more desirable to have a model that is consistently wrong by a small amount than one that makes fewer, but larger errors. One way to produce a metric that \u201camplifies\u201d larger errors by squaring the individual errors and calculating the mean of the squared values. This metric is known as the mean squared error (MSE).</p>"},{"location":"ml-ai/ml-az/regression/#root-mean-squared-error-rmse","title":"Root Mean Squared Error (RMSE)","text":"<p>The mean squared error helps take the magnitude of errors into account, but because it squares the error values, the resulting metric no longer represents the quantity measured by the label. In other words, we can say that the MSE of our model is 6, but that doesn\u2019t measure its accuracy in terms of the number of ice creams that were mispredicted; 6 is just a numeric score that indicates the level of error in the validation predictions.</p> <p></p>"},{"location":"ml-ai/ml-az/regression/#simple-linear-regression","title":"Simple Linear Regression","text":"<ul> <li>Simple Linear Regression Sample Code</li> </ul>"},{"location":"ml-ai/ml-az/regression/#multiple-linear-regression","title":"Multiple Linear Regression","text":"<ul> <li>Multiple Linear Regression Sample Code</li> </ul>"},{"location":"ml-ai/ml-az/regression/#polynomial-regression","title":"Polynomial Regression","text":"<ul> <li>Polynomial Linear Regression Sample Code</li> </ul>"},{"location":"ml-ai/ml-az/regression/#support-vector-regression-svr","title":"Support Vector Regression (SVR)","text":""},{"location":"spark/spark-concept/","title":"Spark","text":""}]}